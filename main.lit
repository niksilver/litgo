@title Litgo - A literate programming processor written in Go

@code_type Go .go
@comment_type // %s


@s Application structure

--- main.go
package main

import (
    @{Imports}
)

@{Package level declarations}

@{Functions}
---


@s Processing content: Basic structure

We start with a file, from which we get a
slice of bytes (our input) but it will be processed
line by line, as strings.
We need to keep track of the (current) file, so we can include
references to it in the generated source.
We will do this by maintaining a state, and process each line with
a given line processor, all the while updating the state.

Each line will be received for processing without its end of line characters.

--- Imports
"bufio"
"fmt"
"io/ioutil"
"github.com/gomarkdown/markdown"
"os"
"strings"
---

--- Package level declarations
type state struct {
    fname string  // Name of file being processed, relative to working dir
    markdown strings.Builder  // Markdown output
    lineNum int
    @{More state fields}
}

---

--- Functions
func newState() state {
    return state{
        @{Field initialisers for state}
    }
}

func processContent(c []byte, s *state, proc func(*state, string)) {
    r := strings.NewReader(string(c))
    sc := bufio.NewScanner(r)
    for sc.Scan() {
        proc(s, sc.Text())
    }
    @{Tidy-up after processing content}
}

func main() {
    s := newState()
    input, err := inputBytes(s.fname)
    if err != nil {
        fmt.Println(err.Error())
        return
    }

    processContent(input, &s, proc)

    @{Check code chunks and maybe abort}

    @{Write out warnings}

    @{Write out code chunks}

    md := []byte(s.markdown.String())
	output := markdown.ToHTML(md, nil, nil)
	fmt.Println(string(output))
}

func inputBytes(fname string) (input []byte, e error) {
    f, err := os.Open(fname)
    if err != nil {
        return nil, err
    }
    defer func() {
        if err := f.Close(); err != nil {
            e = err
        }
    }()
    return ioutil.ReadAll(f)
}

---

For the purposes of both testing and ease of developing our application
we need a generic way of reacting to lines. The process is:

    Line ->    Code processor    ->  Markdown processor
            (May add more lines,
             or drop this line,
             or change the input
             in other ways)

The line processor, which is `proc` in the code above,
should just pass through any markdown, but it
will need to process special commands and it will need to keep a
track of the code as it is assembled in non-linear order.

--- Functions +=
func proc(s *state, line string) {
    s.lineNum ++
    @{Collect lines in code chunks}
    @{Send surviving lines to markdown}
}

---


@s Processing content: Errors and warnings

As part of our evolving processing state we will collect warnings,
such as a chunk appearing without a name. We may also have to stop
at an error. Both are kinds of problems. Warnings will be problems
collected in the state; an error will be returned from any processing.

--- Package level declarations +=
type problem struct {
    fname string
    line int
    msg string
}

---

--- More state fields
warnings []problem
---

--- Write out warnings
for _, w := range s.warnings {
    fmt.Printf("%s: %s: %s\n", w.fname, w.line, w.msg)
}
---


@s Processing content: Collect lines in code chunks

Code chunks start with three backticks, a space, and a name.
They end with three backticks.
Anything within the backticks is to be generated code, and that code
will go into a map, from name to code.
We'll assemble the chunks later.

--- Package level declarations +=
type chunk struct {
    line []int     // Line number where the chunk defined
    code []string  // Lines of code, without newlines
    lines []int    // Line number for each line of code
}

---

--- More state fields +=
inChunk bool  // If we're currently reading a chunk
chunkName string  // Name of current chunk
chunks map[string]*chunk  // All the chunks found so far
---

--- Field initialisers for state
chunks: make(map[string]*chunk),
---

--- Collect lines in code chunks
if s.inChunk && line == "```" {
    s.inChunk = false
} else if s.inChunk {
    ch := s.chunks[s.chunkName]
    s.chunks[s.chunkName].code = append(ch.code, line)
    s.chunks[s.chunkName].lines = append(ch.lines, s.lineNum)
} else if !s.inChunk && strings.HasPrefix(line, "```") {
    s.chunkName = strings.TrimSpace(line[3:])
    if s.chunkName == "" {
        s.warnings = append(s.warnings,
            problem{s.fname, s.lineNum, "Chunk has no name"})
    }
    ch := s.chunks[s.chunkName]
    if ch == nil {
        s.chunks[s.chunkName] = &chunk{}
        ch = s.chunks[s.chunkName]
    }
    s.chunks[s.chunkName].line = append(ch.line, s.lineNum)
    s.inChunk = true
}
---

--- Tidy-up after processing content
if s.inChunk {
    s.warnings = append(s.warnings,
        problem{s.fname, s.lineNum, "Content finished but chunk not closed"})
}
---


@s Processing content: Send surviving lines to markdown

--- Send surviving lines to markdown
s.markdown.WriteString(line + "\n")
---


@s Outputting the code: Checking code chunks

We don't want to output the code and discover half way through we have
a problem with the assembly. So we'll do checks on it first. Checks will be:

* Is every top level chunk a named file?
* Make sure there are no circular inclusions.
* Is every named chunk defined?

(One chunk may have more than one parent, so the structure is more like
a lattice; it's not a tree.)

--- Check code chunks and maybe abort
lat := compileLattice(s.chunks)
errs := make([]error, 0)
if err := assertTopLevelChunksAreFilenames(lat); err != nil {
    errs = append(errs, err)
}
if err := assertNoCycles(lat); err != nil {
    errs = append(errs, err)
}
if err := assertAllChunksDefined(s.chunks, lat); err != nil {
    errs = append(errs, err)
}
if len(errs) > 0 {
    for _, e := range errs {
        fmt.Println(e.Error())
    }
    return
}
---

--- Package level declarations +=
type set map[string]bool

type lattice struct {
    childrenOf map[string]set
    parentsOf map[string]set
}

---

First we'll compile our lattice of chunk names.

--- Functions +=
func compileLattice(chunks map[string]*chunk) lattice {
    lat := lattice{
        childrenOf: make(map[string]set),
        parentsOf: make(map[string]set),
    }

    for name, data := range chunks {
        // Make sure this parent is in the lattice
        if lat.childrenOf[name] == nil {
            lat.childrenOf[name] = make(map[string]bool)
        }
        if lat.parentsOf[name] == nil {
            lat.parentsOf[name] = make(map[string]bool)
        }

        for _, line := range data.code {
            refChunk := referredChunkName(line)
            if refChunk == "" {
                continue
            }

            // Make sure this child is in the lattice
            if lat.childrenOf[refChunk] == nil {
                lat.childrenOf[refChunk] = make(map[string]bool)
            }
            if lat.parentsOf[refChunk] == nil {
                lat.parentsOf[refChunk] = make(map[string]bool)
            }

            // Store the parent/child relationship
            (lat.childrenOf[name])[refChunk] = true
            (lat.parentsOf[refChunk])[name] = true
        }
    }
    return lat
}

func referredChunkName(str string) string {
    str = strings.TrimSpace(str)
    if strings.HasPrefix(str, "@{") && strings.HasSuffix(str, "}") {
        return strings.TrimSpace(str[2:len(str)-1])
    }
    return ""
}

---

How to check if every top level chunk is a filename.
A chunk is at the top level if it's got no parents.

--- Imports +=
"regexp"
---

--- Functions +=
func assertTopLevelChunksAreFilenames(lat lattice) error {
    badNames := make([]string,0)
    for ch, pars := range lat.parentsOf {
        if len(pars) == 0 && !isFilename(ch) {
            badNames = append(badNames, ch)
        }
    }

    if len(badNames) == 0 {
        // No error
        return nil
    }

    msg := "Found top level chunk which isn't a filename: %s"
    if len(badNames) > 1 {
        msg = "Found top level chunks which aren't filenames: %s"
    }
    return fmt.Errorf(msg, strings.Join(badNames, ","))
}

func isFilename(s string) bool {
    match, _ := regexp.MatchString("\\.\\S+$", s)
    return match
}

---

How to make sure there are no cycles in our chunk inclusion:

1. Select all the top level chunks.
2. Make a singleton list of each one. This is a list of "paths".
   These paths are our existing "paths".
3. As long as we've got some existing paths...
  1. We will create some new paths. Initially there are no new paths.
  2. For each existing path:
    1. Pick the last element.
    2. Find its children.
    3. If there are no children continue with the next round of the loop.
    3. If this child appears earlier in the path that's a cycle.
       Terminate with an error message.
    4. Add to our list of new paths: Each new path is the current
       path plus the child added to the end.
       For example, if our current path is {a, b, c, d} and the
       children of d are e1, e2 and e3, then our new paths are
       {a, b, c, d, e1} and {a, b, c, d, e2} and {a, b, c, d, e3}.
  3. Our list of new paths becomes our existing paths.
4. If we've reached this stage then there are no cycles. All is well.

--- Functions +=
func assertNoCycles(lat lattice) error {
    // Find the top level chunks
    top := topLevelChunks(lat)

    // Make a singleton list of these, which is our initial list of paths
    paths := make([][]string, 0)
    for _, par := range top {
        paths = append(paths, []string{par})
    }

    // As long as we've got some existing paths...
    for len(paths) > 0 {
        // New paths, initially none
        nPaths := make([][]string, 0)

        // For each existing path...
        for _, path := range paths {
            // Pick the last element and find its children
            lastElt := path[len(path)-1]
            chs := make([]string, 0)
            for key, _ := range lat.childrenOf[lastElt] {
                chs = append(chs, key)
            }

            // If there are no children, go on to the next path
            if len(chs) == 0 {
                continue
            }

            // Terminate with an error if the elt appears earlier in the path
            for i := 0; i < len(path)-1; i++ {
                if path[i] == lastElt {
                    return fmt.Errorf("Found cyclic chunks: %s",
                        strings.Join(path[i:], " -> "))
                }
            }

            // Add our list of new paths. One new path for each child
            for _, ch := range chs {
                nPath := append(path, ch)
                nPaths = append(nPaths, nPath)
            }
        }

        // Our list of new paths becomes the list of paths to work on
        paths = nPaths
    }

    // If we've got here, then there are no cycles
    return nil
}

func topLevelChunks(lat lattice) []string {
    top := make([]string, 0)
    for ch, pars := range lat.parentsOf {
        if len(pars) == 0 {
            top = append(top, ch)
        }
    }
    return top
}

---

If a named chunk isn't defined then (a) it's in the lattice struct,
but (b) it doesn't have a key in the `chunks` field of the state struct.

--- Functions +=
func assertAllChunksDefined(chunks map[string]*chunk, lat lattice) error {
    missing := make([]string, 0)
    for par, _ := range lat.childrenOf {
        if chunks[par] == nil {
            missing = append(missing, par)
        }
    }

    if len(missing) == 0 {
        return nil
    }

    s := ""
    if len(missing) >= 2 {
        s = "s"
    }
    return fmt.Errorf("Chunk%s not defined: %s",
        s, strings.Join(missing, ", "))
}

---


@s Outputting: Code chunks

To output our code chunks we need three things:
* The top level chunks (filenames); and
* The chunks themselves; and
* A writer factory: i.e. a way to create an appropriate io.StringWriter
  for a given filename.
  (This would normally be to a file, but might be a string builder for
  testing purposes.)

Then for each filename we create its writer, and write its chunks.
Each time we include a chunk we should indent it by the same indent
as the chunk reference was indented by---the actual string (tabs or spaces),
not just what we think the indent count is.

The writing process will return any error.

--- Write out code chunks
top := topLevelChunks(lat)
err = writeChunks(top, s.chunks, makeChunkWriter)
if err != nil {
    fmt.Println(err.Error())
    return
}
---

--- Imports +=
"io"
---

--- Functions +=
func writeChunks(top []string, chunks map[string]*chunk, wf func(string) (io.StringWriter, error)) error {
    for _, name := range top {
        w, err := wf(name)
        if err != nil {
            return err
        }
        err = writeChunk(name, chunks, w, "")
        if err != nil {
            return err
        }
    }

    // No errors - all okay
    return nil
}

func makeChunkWriter(name string) (io.StringWriter, error) {
    f, err := os.Open(name)
    if err != nil {
        return nil, err
    }
    return bufio.NewWriter(f), nil
}

---

When we write one chunk we need to follow references to other chunks
which are included in that.

--- Functions +=
func writeChunk(name string,
        chunks map[string]*chunk,
        w io.StringWriter,
        indent string) error {

    chunk := *chunks[name]
    for _, line := range chunk.code {
        var err error
        if ref := referredChunkName(line); ref != "" {
            iPos := strings.Index(line, "@")
            err = writeChunk(ref, chunks, w, line[0:iPos] + indent)
        } else {
            _, err = w.WriteString(indent + line + "\n")
        }
        if err != nil {
            return err
        }
    }
    return nil
}

---

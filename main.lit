@title Litgo - A literate programming processor written in Go

@code_type Go .go
@comment_type // %s


@s Application structure

--- main.go
package main

import (
    "bufio"
    "flag"
    "fmt"
    "github.com/gomarkdown/markdown"
    "io"
    "os"
    "path/filepath"
    "reflect"
    "regexp"
    "sort"
    "strconv"
    "strings"
)

@{Package level declarations}

@{Functions}
---

And here is the main loop:

--- Functions

func init() {
    @{Flag initialisation}
}

func main() {
    @{Set up the initial state}

    @{Read the content}

    @{Write out the code files}

    @{Write out the markdown as HTML}
}

---


@s High level structures: State and document

There are three major structures:
* The state will keep track where we are reading the input file(s).
  It's more ephemeral (only useful when reading in) and dynamic.
* The doc will keep track of the document structures as we assemble them,
  including chunks and how they relate to each other, plus general config.
  It grows towards a single complete picture.

The doc needs to capture things like line numbers, but also (because
we may be dealing with multiple input files - a book with chapters)
which input file those things come from.

--- Set up the initial state
s := newState()
d := newDoc()

@{Update the structs according to the command line}
---

--- Package level declarations
type state struct {
    // Tracking
    book string  // Name of the top level book file, or empty if none.
    inName string  // Name of file being processed, relative to working dir
    outName string  // Name of final file to write to
    inNames []string  // Name of all input files, including the first
    lineNum int  // Current line number
    chunkName string  // Name of current chunk
    inChunk bool  // If we're currently reading a chunk
    warnings []warning  // Warnings we're collecting
    sec section  // Current section being read
    // Function for processing a line
    proc func(*state, *doc, string)
}

type doc struct {
    // Markdown after the initial read, per input file
    markdown map[string]*strings.Builder
    chunks map[string]*chunk  // All the chunks found so far
    // Lines where a named chunk starts, per input file
    chunkStarts map[string]map[int]string
    // Lines where other chunks are called in, per input file
    chunkRefs map[string]map[int]chunkRef
    lat lattice  // A lattice of chunk parent/child relationships
    // Lines where a section starts, per input file
    secStarts map[string]map[int]section
    // Config
    lineDir string  // The string pattern for line directives
    docOutDir string  // Output directory for the translated markdown
    // Function for opening a file to write to and close
    writeCloser func(string) (io.WriteCloser, error)
}


---

--- Functions +=
func newState() state {
    return state {
        proc: proc,
    }
}

func newDoc() doc {
    return doc {
        markdown: make(map[string]*strings.Builder),
        chunks: make(map[string]*chunk),
        chunkStarts: make(map[string]map[int]string),
        chunkRefs: make(map[string]map[int]chunkRef),
        secStarts: make(map[string]map[int]section),
        writeCloser: getWriteCloser,
    }
}

---

@s Processing the content: Overview

There is one pass reading the content, which is just designed to
assemble the basic data structures, make some light amendments,
check for problems, and prepare for output (code and markup).

--- Read the content
@{Do a first pass through all the content}

@{Check code chunks and maybe abort}

@{Write out warnings}
---


@s Processing the content: First pass, basic file handling

We open a file, process the content, and close the file.
If the top file is book then we will also collect links to `.md` files
and follow those, too. But we'll only follow those links in the book
file, not any others.

When reading a book, future files to read in are stored in `s.nextIn`.
We will keep looping through the `nextIn` files until there are none left.

If the filename is `"-"` then we use Stdin.

--- Do a first pass through all the content
if err := firstPassForAll(&s, &d, fileReader); err != nil {
    fmt.Println(err.Error())
    return
}
---

--- Functions +=
func firstPassForAll(s *state, d *doc, fileRdr func(string) (io.ReadCloser, error)) error {
    for i := 0; i < len(s.inNames); i++ {
        s.setInName(s.inNames[i])
        if err := firstPass(s, d, fileRdr); err != nil {
            return err
        }
        s.book = ""
    }
    return nil
}

func firstPass(s *state, d *doc, fileRdr func(string) (io.ReadCloser, error)) error {
    fReader, err := fileRdr(s.inName)
    if err != nil {
        return err
    }
    processContent(fReader, s, d)
    if err := fReader.Close(); err != nil {
        return err
    }
    return nil
}

func fileReader(fName string) (io.ReadCloser, error) {
    var f *os.File
    var err error
    if fName == "-" {
        f = os.Stdin
    } else {
        f, err = os.Open(fName)
    }

    return f, err
}

---


@s Processing content: Reading the document

When we process the content on the first pass through it's a slice of bytes.
We turn that into lines (without the newline characters) and
read those lines one at a time, updating the document data structure
(including relationships between code chunks) as we go.

--- Functions +=
func processContent(r io.Reader, s *state, d *doc) {
    sc := bufio.NewScanner(r)
    for sc.Scan() {
        s.proc(s, d, sc.Text())
    }

    if s.inChunk {
        s.warnings = append(s.warnings,
            warning{s.inName, s.lineNum,
            "Content finished but chunk not closed"})
    }
}

---

For the purposes of both testing and ease of developing our application
we need a generic way of reacting to lines. The process is:

    Line ->    Process    ->  Updated doc structure
                              Minor line amendments

The line processor, which is `proc` in the code above and below,
should just pass through most markdown, but it
will amend some lines (e.g. adding section anchors), and it
will need to process special commands.

--- Functions +=
func proc(s *state, d *doc, line string) {
    s.lineNum ++
    @{Track chapter files to read}
    @{Track and mark section changes}
    @{Collect lines in code chunks}
    if _, okay := d.markdown[s.inName]; !okay {
        d.markdown[s.inName] = &strings.Builder{}
    }
    d.markdown[s.inName].WriteString(line + "\n")
}

---


@s Processing content: Warnings

As part of our evolving processing state we will collect warnings,
such as a chunk appearing without a name.

--- Package level declarations +=
type warning struct {
    fName string
    line int
    msg string
}

---

--- Write out warnings
for _, w := range s.warnings {
    fmt.Printf("%s: %d: %s\n", w.fName, w.line, w.msg)
}
---


@s Sections: Definitions and basic functions

We need to track sections to be able to explain where code chunks are used
and added to.

A line represents a new section (or subsection) when it starts with a number
of `#`s, some whitespace, and some text. So a section will
be a structured object with functions to convert to and from strings.


--- Package level declarations +=
type section struct {
    inName string
    nums []int
    text string
}

---

--- Functions +=
func (s *section) toString() string {
    if len(s.nums) == 0 {
        return "0"
    }

    return s.numsToString() + " " + s.text
}

func (s *section) numsToString() string {
    num := ""
    for i, n := range s.nums {
        num += strconv.Itoa(n)
        if i < len(s.nums)-1 {
            num += "."
        }
    }
    return num
}

// next returns the section, and if it's changed, given a line of markdown.
func (s *section) next(line string) (section, bool) {
    re, _ := regexp.Compile("(#+)\\s+(.*)")
    find := re.FindStringSubmatch(line)
    if len(find) < 2 {
        return *s, false
    }

    oldLevel := len(s.nums)
    newLevel := len(find[1])
    nums := make([]int, newLevel)
    if oldLevel < newLevel {
        for i := 0; i < oldLevel; i++ {
            nums[i] = s.nums[i]
        }
        nums[newLevel-1] = 1
    } else {
        for i := 0; i < newLevel-1; i++ {
            nums[i] = s.nums[i]
        }
        nums[newLevel-1] = s.nums[newLevel-1] + 1
    }

    return section{s.inName, nums, find[2]}, true
}

---


@s Sections: Tracking and marking

We will track section changes in our state.
Note we'll always update the current section's input filename if we
change files, even if there hasn't been a new section heading since
changing file.

--- Track and mark section changes
if !s.inChunk && strings.HasPrefix(line, "#") {
    var changed bool
    s.sec, changed = s.sec.next(line)
    if changed {
        line = strings.Repeat("#", len(s.sec.nums)) +
                " <a name=\"sec" + s.sec.numsToString() + "\"></a>" +
                s.sec.toString()
        if _, okay := d.secStarts[s.inName]; !okay {
            d.secStarts[s.inName] = make(map[int]section)
        }
        d.secStarts[s.inName][s.lineNum] = s.sec
    }
}
---

--- Functions +=
func (s *state) setInName(name string) *state {
    s.inName = name
    s.sec.inName = name
    return s
}

func (s *state) setFirstInName(name string) *state {
    s.inName = name
    s.sec.inName = name
    s.inNames = []string{ name }
    return s
}

---


@s Processing content: Watching for links to chapter files

If a line of markdown contains a link to a .md file then
that's a sign we should add the file to our input list.
We should make sure any link we follow is relative to the
input file.

In a line of markdown, the regular expression to find a link is:

* A `]` character followed by
* a `)` character followed by
* the filename followed by
* an optional space and title in double quotes, followed by
* A `)` character.

--- Track chapter files to read
nextInName := markdownLink(line)
if s.book != "" && !s.inChunk && nextInName != "" {
    s.inNames = append(s.inNames, nextInName)
}
---

--- Functions +=
func markdownLink(line string) string {
    titleRE := `(\s+"[^"]*")?`
    re, _ := regexp.Compile("\\]\\(([^)]+\\.md)" + titleRE + "\\)")
    s := re.FindStringSubmatch(line)
    if len(s) == 0 {
        return ""
    }
    return s[1]
}

---


@s Processing content: Collect lines in code chunks

Code chunks start with three backticks, a space, and a name.
They end with three backticks.
Anything within the backticks is to be generated code, and that code
will go into a map, from name to code.
We'll assemble the chunks later.

--- Package level declarations +=
type chunk struct {
    def []chunkDef // Each place where the chunk is defined
    cont []chunkCont // Each line of code
}

// Where the chunk is defined: input file name, line number, section
type chunkDef struct {
    inName string
    line int
    sec section
}

// A line of chunk content: input file name, line number, and the code line itself
type chunkCont struct {
    inName string
    lNum int
    code string
}
---

--- Collect lines in code chunks
if s.inChunk && line == "```" {
    s.inChunk = false
    @{Capture data for post-chunk references}
} else if s.inChunk {
    d.chunks[s.chunkName].cont = append(
            d.chunks[s.chunkName].cont,
            chunkCont {
                inName: s.inName,
                lNum: s.lineNum,
                code: line,
            })
} else if !s.inChunk && strings.HasPrefix(line, "```") {
    s.chunkName = strings.TrimSpace(line[3:])
    if s.chunkName == "" {
        s.warnings = append(s.warnings,
            warning{s.inName, s.lineNum, "Chunk has no name"})
    }
    ch := d.chunks[s.chunkName]
    if ch == nil {
        d.chunks[s.chunkName] = &chunk{}
        ch = d.chunks[s.chunkName]
    }
    if _, okay := d.chunkStarts[s.inName]; !okay {
        d.chunkStarts[s.inName] = make(map[int]string)
    }
    d.chunkStarts[s.inName][s.lineNum] = s.chunkName
    d.chunks[s.chunkName].def = append(
            d.chunks[s.chunkName].def,
            chunkDef {
                inName: s.inName,
                line: s.lineNum,
                sec: s.sec,
            })
    s.inChunk = true
}
---


@s Processing content: Flagging lines for post-chunk references

After each code chunk we want some text to say it was "Added to in
sections X, Y and Z." However, as we process the content the first
time through we don't know what X, Y and Z are, so the best we
can do is note the fact that "after line number A we want to say something
about chunk B in section C." Then when we output markdown line number A
we follow it with the appropriate text.

--- Package level declarations +=
type chunkRef struct {
    name string
    thisSec section
}

---

--- Capture data for post-chunk references
if _, okay := d.chunkRefs[s.inName]; !okay {
    d.chunkRefs[s.inName] = make(map[int]chunkRef)
}
d.chunkRefs[s.inName][s.lineNum] = chunkRef{ s.chunkName, s.sec }
---


@s Processing content: Checking code chunks

We don't want to output the code and discover half way through we have
a problem with the assembly. So we'll do checks on it first. Checks will be:

* Is every top level chunk a named file?
* Make sure there are no circular inclusions.
* Is every named chunk defined?

(One chunk may have more than one parent, so the structure is more like
a lattice; it's not a tree.)

--- Check code chunks and maybe abort
d.lat = compileLattice(d.chunks)
errs := make([]error, 0)
if err := assertTopLevelChunksAreFilenames(d.lat); err != nil {
    errs = append(errs, err)
}
if err := assertNoCycles(d.lat); err != nil {
    errs = append(errs, err)
}
if err := assertAllChunksDefined(d.chunks, d.lat); err != nil {
    errs = append(errs, err)
}
if len(errs) > 0 {
    for _, e := range errs {
        fmt.Println(e.Error())
    }
    return
}
---

--- Package level declarations +=
type set map[string]bool

type lattice struct {
    childrenOf map[string]set
    parentsOf map[string]set
}

---

First we'll compile our lattice of chunk names.

--- Functions +=
func compileLattice(chunks map[string]*chunk) lattice {
    lat := lattice{
        childrenOf: make(map[string]set),
        parentsOf: make(map[string]set),
    }

    for name, data := range chunks {
        // Make sure this parent is in the lattice
        if lat.childrenOf[name] == nil {
            lat.childrenOf[name] = make(map[string]bool)
        }
        if lat.parentsOf[name] == nil {
            lat.parentsOf[name] = make(map[string]bool)
        }

        for _, cont := range data.cont {
            refChunk := referredChunkName(cont.code)
            if refChunk == "" {
                continue
            }

            // Make sure this child is in the lattice
            if lat.childrenOf[refChunk] == nil {
                lat.childrenOf[refChunk] = make(map[string]bool)
            }
            if lat.parentsOf[refChunk] == nil {
                lat.parentsOf[refChunk] = make(map[string]bool)
            }

            // Store the parent/child relationship
            (lat.childrenOf[name])[refChunk] = true
            (lat.parentsOf[refChunk])[name] = true
        }
    }
    return lat
}

func referredChunkName(str string) string {
    str = strings.TrimSpace(str)
    if strings.HasPrefix(str, "@{") && strings.HasSuffix(str, "}") {
        return strings.TrimSpace(str[2:len(str)-1])
    }
    return ""
}

---

How to check if every top level chunk is a filename.
A chunk is at the top level if it's got no parents.

--- Functions +=
func assertTopLevelChunksAreFilenames(lat lattice) error {
    badNames := make([]string,0)
    for ch, pars := range lat.parentsOf {
        if len(pars) == 0 && !isFilename(ch) {
            badNames = append(badNames, ch)
        }
    }

    if len(badNames) == 0 {
        // No error
        return nil
    }

    msg := "Found top level chunk which isn't a filename: %s"
    if len(badNames) > 1 {
        msg = "Found top level chunks which aren't filenames: %s"
    }
    return fmt.Errorf(msg, strings.Join(badNames, ","))
}

func isFilename(s string) bool {
    match, _ := regexp.MatchString("\\.\\S+$", s)
    return match
}

---

How to make sure there are no cycles in our chunk inclusion:

1. Select all the top level chunks.
2. Make a singleton list of each one. This is a list of "paths".
   These paths are our existing "paths".
3. As long as we've got some existing paths...
  1. We will create some new paths. Initially there are no new paths.
  2. For each existing path:
    1. Pick the last element.
    2. Find its children.
    3. If there are no children continue with the next round of the loop.
    3. If this child appears earlier in the path that's a cycle.
       Terminate with an error message.
    4. Add to our list of new paths: Each new path is the current
       path plus the child added to the end.
       For example, if our current path is {a, b, c, d} and the
       children of d are e1, e2 and e3, then our new paths are
       {a, b, c, d, e1} and {a, b, c, d, e2} and {a, b, c, d, e3}.
  3. Our list of new paths becomes our existing paths.
4. If we've reached this stage then there are no cycles. All is well.

--- Functions +=
func assertNoCycles(lat lattice) error {
    // Find the top level chunks
    top := topLevelChunks(lat)

    // Make a singleton list of these, which is our initial list of paths
    paths := make([][]string, 0)
    for _, par := range top {
        paths = append(paths, []string{par})
    }

    // As long as we've got some existing paths...
    for len(paths) > 0 {
        // New paths, initially none
        nPaths := make([][]string, 0)

        // For each existing path...
        for _, path := range paths {
            // Pick the last element and find its children
            lastElt := path[len(path)-1]
            chs := make([]string, 0)
            for key, _ := range lat.childrenOf[lastElt] {
                chs = append(chs, key)
            }

            // If there are no children, go on to the next path
            if len(chs) == 0 {
                continue
            }

            // Terminate with an error if the elt appears earlier in the path
            for i := 0; i < len(path)-1; i++ {
                if path[i] == lastElt {
                    return fmt.Errorf("Found cyclic chunks: %s",
                        strings.Join(path[i:], " -> "))
                }
            }

            // Add our list of new paths. One new path for each child
            for _, ch := range chs {
                nPath := append(path, ch)
                nPaths = append(nPaths, nPath)
            }
        }

        // Our list of new paths becomes the list of paths to work on
        paths = nPaths
    }

    // If we've got here, then there are no cycles
    return nil
}

func topLevelChunks(lat lattice) []string {
    top := make([]string, 0)
    for ch, pars := range lat.parentsOf {
        if len(pars) == 0 {
            top = append(top, ch)
        }
    }
    return top
}

---

If a named chunk isn't defined then (a) it's in the lattice struct,
but (b) it doesn't have a key in the `chunks` field of the state struct.

--- Functions +=
func assertAllChunksDefined(chunks map[string]*chunk, lat lattice) error {
    missing := make([]string, 0)
    for par, _ := range lat.childrenOf {
        if chunks[par] == nil {
            missing = append(missing, par)
        }
    }

    if len(missing) == 0 {
        return nil
    }

    s := ""
    if len(missing) >= 2 {
        s = "s"
    }
    return fmt.Errorf("Chunk%s not defined: %s",
        s, strings.Join(missing, ", "))
}

---


@s Outputting the code: Basic output

To output our code chunks we need three things:
* The top level chunks (filenames); and
* The state, including chunks themselves and the wider data about
  whether line directives should be printed, the current filename, etc; and
* A way to get a WriteCloser:
  i.e. a way to create something that will open a writable file for
  a given filename (or string buffer for testing) and then close it later.

Then for each filename we create its create its WriteCloser,
and write its chunk strings.

Each time we include a chunk we should indent it by the same indent
as the chunk reference was indented by---the actual string (tabs or spaces),
not just what we think the indent count is.

If the line directive string (`lineDir`) is anything other than an empty string
that means we need to output them in that format.

The writing process will return any error.

--- Write out the code files
top := topLevelChunks(d.lat)
err := d.writeChunks(top, d.lineDir, s.inName)
if err != nil {
    fmt.Println(err.Error())
    return
}
---

--- Functions +=
func (d *doc) writeChunks(
        top []string,
        lineDir string,
        fName string) error {

    for _, name := range top {
        wc, err := d.writeCloser(name)
        if err != nil {
            return err
        }
        bw := bufio.NewWriter(wc)
        err = d.writeChunk(name, bw, lineDir, "", fName)
        if err != nil {
            wc.Close()
            return err
        }
        if err := bw.Flush(); err != nil {
            wc.Close()
            return err
        }
        if err := wc.Close(); err != nil {
            return err
        }
    }

    // No errors - all okay
    return nil
}

func getWriteCloser(name string) (io.WriteCloser, error) {
    return os.Create(name)
}

---

When we write one chunk we need to

* Include a line directive, if any
* follow references to other chunks which are included in that.

--- Functions +=
func (d *doc) writeChunk(name string,
        w *bufio.Writer,
        lineDir string,
        indent string,
        fName string) error {

    chunk := d.chunks[name]
    for _, cont := range chunk.cont {
        code := cont.code
        var err error
        if ref := referredChunkName(code); ref != "" {
            iPos := strings.Index(code, "@")
            err = d.writeChunk(ref, w, lineDir, code[0:iPos] + indent, fName)
        } else {
            lNum := cont.lNum
            indentHere := initialWS(code)
            dir := lineDirective(lineDir, indent + indentHere, fName, lNum)
            _, err = w.WriteString(dir + indent + code + "\n")
        }
        if err != nil {
            return err
        }
    }
    return nil
}

func initialWS(code string) string {
    whitespace, _ := regexp.Compile("^\\s*")
    res := whitespace.FindStringSubmatch(code)
    if len(res) == 0 {
        return ""
    }
    return res[0]
}

---


@s Outputting the code: Line directives

A line directive is only output if it's non-empty.

--- Functions +=
func lineDirective(dir string, indent string, fName string, n int) string {
    if dir == "" {
        return ""
    }

    out := ""
    perc := false
    for _, r := range dir {
        if perc {
            switch r {
            case '%': out += "%"
            case 'i': out += indent
            case 'f': out += fName
            case 'l': out += fmt.Sprintf("%d", n)
            default: out += string(r)
            }
            perc = false
        } else if r == '%' {
            perc = true
        } else {
            out += string(r)
            perc = false
        }
    }
    return out + "\n"
}

---


@s Outputting the markdown: Basic output

When outputting the markdown there is an outer loop and an inner task.

For the outer loop we want to go through each input file and
write out the corresponding HTML. There may be a "doc out dir" which
tells us which output directory to write the documentation out to,
in which case the output file location is:

* For the first (book) file, the doc out dir + the base filename;
* For chapter files, the doc out dir + the whole filename referenced
  in the book file.

If there's no doc out dir then each file location is:

* For the first (book) file, the filename;
* For the chapter files, the whole filename relative to the directory
  of the book file.

--- Write out the markdown as HTML
if err := writeAllMarkdown(s.inNames, &d); err != nil {
    fmt.Print(err.Error())
    return
}
---

--- Functions +=
func writeAllMarkdown(inNames []string, d *doc) error {
    for i, fullOutName := range outNames(d.docOutDir, inNames) {
        if err := writeHTML(inNames[i], fullOutName, d); err != nil {
            return err
        }
    }
    return nil
}

func outNames(outDir string, inNames []string) []string {
    names := make([]string, len(inNames))

    if outDir == "" {
        in0Dir := filepath.Dir(inNames[0])
        for i, inName := range inNames {
            if i == 0 {
                names[i] = outName(inName)
            } else {
                names[i] = outName(filepath.Join(in0Dir, inName))
            }
        }
    } else {
        for i, inName := range inNames {
            if i == 0 {
                in0Base := filepath.Base(inNames[0])
                names[i] = outName(filepath.Join(outDir, in0Base))
            } else {
                names[i] = outName(filepath.Join(outDir, inName))
            }
        }
    }

    return names
}

---

For the inner task we could just output the relevant markdown for that
input file, but we also want to amend it (to create "final" markdown)
to:

* Amend each start-of-chunk section so it includes the coding language;
* insert post-chunk references;

and we can do that only if we output the markdown a line at a time.

--- Functions +=
func writeHTML(inName string, fullOutName string, d *doc) error {
    md := finalMarkdown(inName, d).String()
    output := markdown.ToHTML([]byte(md), nil, nil)
    outFile, err := d.writeCloser(fullOutName)
    if err != nil {
        return err
    }
    _, err = io.WriteString(outFile, string(output))
    if err != nil {
        outFile.Close()
        return err
    }
    return outFile.Close()
}

func finalMarkdown(inName string, d *doc) *strings.Builder {
    b := strings.Builder{}
    r := strings.NewReader(d.markdown[inName].String())
    sc := bufio.NewScanner(r)
    count := 0
    for sc.Scan() {
        count ++
        mkup := sc.Text()
        @{Amend chunk starts to include coding language}
        b.WriteString(mkup + "\n")
        @{Include post-chunk reference if necessary}
    }
    return &b
}

---


@s Outputting the markdown: Including the coding language per chunk

The start of any code chunk should be the backticks followed immediately
(no spaces) by the language. For top level chunks this is the suffix
of the filename. For other chunks we need to work up the lattice until
we find the top chunk.

--- Amend chunk starts to include coding language
if name, okay := d.chunkStarts[inName][count]; okay {
    mkup = backticks(mkup)
    top := topOf(name, d.lat)
    re, _ := regexp.Compile("[-_a-zA-Z0-9]*$")
    langs := re.FindStringSubmatch(top)
    if langs != nil {
        mkup += langs[0]
    }
}
---

--- Functions +=
// topOf takes a chunk name and returns the top-most parent name
func topOf(name string, lat lattice) string {
    for len(lat.parentsOf[name]) > 0 {
        // Get any parent of this chunk
        for par := range lat.parentsOf[name] {
            name = par
            break
        }
    }
    return name
}

// backticks gets all the backticks at the start of a string
func backticks(mkup string) string {
    out := ""
    for _, roon := range mkup {
        if roon != '`' {
            return out
        }
        out += "`"
    }
    return out
}

---

@s Outputting the markdown: Including chunk references

When outputting the markdown we may be outputting a line that's the
end of a chunk, in which case we'll see what post-chunk references
need to be inserted. It may be an empty string.

There are two kinds of post-chunk references: "Added to in..."
(siblings) and "Used in..." (parents). Both will be presented
in its own paragraph.

--- Include post-chunk reference if necessary
if ref, ok := d.chunkRefs[inName][count]; ok {
    str1 := addedToChunkRef(d, ref)
    b.WriteString(str1)
    str2 := usedInChunkRef(d, ref)
    b.WriteString(str2)
}
---

For "Added to in...", when we list the
section references we want to omit this chunk,
but only once in case the chunk is added to elsewhere in this section.

--- Functions +=
func addedToChunkRef(d *doc, ref chunkRef) string {
    chunk := d.chunks[ref.name]
    secs := make([]section, len(chunk.def))
    for i, def := range chunk.def {
        secs[i] = def.sec
    }

    for i, sec := range secs {
        if reflect.DeepEqual(ref.thisSec, sec) {
            secs = append(secs[:i], secs[i+1:]...)
            break
        }
    }

    if len(secs) == 0 {
        return ""
    }

    return "\nAdded to in " + sectionsAsEnglish(secs) + ".\n\n"
}

func sectionsAsEnglish(secs []section) string {
    list := ""
    for i, sec := range secs {
        list +=sec.numsToString()
        if i < len(secs)-2 {
            list += ", "
        } else if i == len(secs)-2 {
            list += " and "
        }
    }

    prefix := "section "
    if len(secs) > 1 {
        prefix = "sections "
    }

    return prefix + list
}

---

For "Used in..." we want to list the parent(s) of this chunk.
We will use the chunk lattice for that.
However, the lattice only gives the names of a chunk's parents;
we need to know which section(s) it's mentioned in, and a
chunk may be split over several sections. So
we'll need to scan through the lines of a named parent, and
find any line including the child. For each line found:

* find its corresponding line number,
* track back to where that chunk starts, and
* find the section.

Then add that to the list of parent sections. Phew!

--- Functions +=
func usedInChunkRef(d *doc, ref chunkRef) string {
    secs := make([]section, 0)

    // Get the sections
    for parName, _ := range d.lat.parentsOf[ref.name] {
        chunk := d.chunks[parName]
        for _, cont := range chunk.cont {
            if referredChunkName(cont.code) == ref.name {
                var sec section
                for _, def := range chunk.def {
                    if def.line < cont.lNum {
                        sec = def.sec
                    }
                }
                secs = append(secs, sec)
            }
        }
    }

    if len(secs) == 0 {
        return ""
    }

    // Sort the sections
    sort.Slice(secs, func(i, j int) bool { return secs[i].less(secs[j]) })

    return "\nUsed in " + sectionsAsEnglish(secs) + ".\n\n"
}

func (s1 *section) less(s2 section) bool {
    n1, n2 := s1.nums, s2.nums
    var limit int
    if len(n1) < len(n2) {
        limit = len(n1)
    } else {
        limit = len(n2)
    }

    for i := 0; i < limit; i++ {
        switch {
        case n1[i] < n2[i]:
            return true
        case n1[i] > n2[i]:
            return false
        }
    }
    return len(n1) < len(n2)
}

---


@s Read the command line

The command line is:

    cmd [--book[=true|false]] [--line-dir <ldir>]
        [--doc-out-dir <docoutdir>] <input-file>

      <input-file> can be - (or omit it) to indicate stdin.

      --book if the input file is a book, in which case links
          to .md files are followed for that file.
      <ldir> is the line directive to preceed each code line.
          Use %f for filename, %l for line number,
          %i to include indentation, %% for percent sign.
      <docoutdir> is the directory in which to write the documentation.

--- Package level declarations +=
var book bool
var lDir string
var docOutDir string

---

--- Flag initialisation
flag.BoolVar(&book, "book", false, "If the input file is a book")
flag.StringVar(&lDir, "line-dir", "", "Pattern for line directives")
flag.StringVar(&docOutDir, "doc-out-dir", "", "Directory for documentation output")
---

--- Update the structs according to the command line
flag.Parse()
if flag.NArg() == 0 {
    s.setFirstInName("-")
} else if flag.NArg() == 1 {
    s.setFirstInName(flag.Arg(0))
} else if flag.NArg() > 1 {
    fmt.Print("Too many arguments\n\n")
    printHelp()
    return
}
if book {
    s.book = s.inName
}
d.lineDir = lDir
d.docOutDir = docOutDir
---

--- Functions +=
func printHelp() {
    msg := `litgo [--book[=true|false]] [--line-dir <ldir>]
    [-doc-out-dir <dir>] <input-file>

    <input-file> can be - (or be omitted) to indicate stdin.

    --book[=true|false]
        Says if the input file is a book, in which case links
        to .md files are followed for that file.
    --line-dir <ldir>
        <ldir> is the line directive to preceed each code line.
        Use %f for filename, %l for line number,
        %i to include indentation, %% for percent sign.
    --doc-out-dir <dir>
        Output directory for the literate documentation.
`
    fmt.Printf(msg)
}

func outName(fName string) string {
    if fName == "" || fName == "-" || fName == "." {
        fName = "out"
    }
    ext := filepath.Ext(fName)
    if ext != "" {
        fName = fName[0:len(fName)-len(ext)]
    }
    return fName + ".html"
}

---


